{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d89cf9e5-b965-49dd-9569-2b1b9ff89dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_root=\"./szunyog_hangok_25_01_14\" # Root folder containing input recordings\n",
    "output_root=\"./szunyog_hangok_25_01_14_preprocessed_database_AST\" # Root folder for saving outputs\n",
    "\n",
    "\n",
    "MODEL_PATH = \"b_mosquito/results_AST_b_mosquito_25_01_21-full/checkpoint-3966/\" # Path to the trained AST model checkpoint\n",
    "\n",
    "classification_threshold=0.9 # Probability threshold to classify as 'mosquito'\n",
    "b_write_csv=True # Whether to save the output CSV file\n",
    "b_save_segments=True # Whether to save the detected .wav segments\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "381ca6f3-ef37-463c-9bdc-b1cdc3c096bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from scipy.signal import butter, filtfilt\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "\n",
    "# Supported audio file formats\n",
    "supported_formats = [\".wav\"]\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_root, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd37f7f2-e3ab-4762-bf32-69aefc721525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ASTForAudioClassification(\n",
       "  (audio_spectrogram_transformer): ASTModel(\n",
       "    (embeddings): ASTEmbeddings(\n",
       "      (patch_embeddings): ASTPatchEmbeddings(\n",
       "        (projection): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): ASTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ASTLayer(\n",
       "          (attention): ASTAttention(\n",
       "            (attention): ASTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ASTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ASTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ASTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  )\n",
       "  (classifier): ASTMLPHead(\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dense): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load pretrained model and processor\n",
    "label2id = {'not':0, 'mosquito':1}\n",
    "id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "from transformers import AutoProcessor, AutoModelForAudioClassification\n",
    "processor = AutoProcessor.from_pretrained(MODEL_PATH)\n",
    "\n",
    "model = AutoModelForAudioClassification.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    num_labels=2,  # Number of classes\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "ignore_mismatched_sizes=True)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model=model.to(device)\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d1a292e-7d03-4c4c-975c-b77c30705a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_audio_chunks(input_file):\n",
    "    \"\"\"\n",
    "    Read audio file, determine number of channels, split into 1-second chunks with 0.5-second overlap.\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    metadata = []\n",
    "    try:\n",
    "        # Load audio file\n",
    "        audio = AudioSegment.from_file(input_file)\n",
    "\n",
    "        # Determine the number of channels\n",
    "        num_channels = audio.channels\n",
    "        print(f\"File: {input_file}, Number of channels: {num_channels}\")\n",
    "        \n",
    "        #if num_channels!=channel_num:\n",
    "        #    print(\"incorrect channel number\")\n",
    "        #    return  [], [], num_channels\n",
    "\n",
    "        # Separate all channels\n",
    "        separated_channels = audio.split_to_mono()\n",
    "\n",
    "        for channel_index, channel_audio in enumerate(separated_channels):\n",
    "            #if channel_index<3:\n",
    "            #    continue\n",
    "\n",
    "            # Convert to 8kHz\n",
    "            #channel_audio = channel_audio.set_frame_rate(8000)\n",
    "            channel_audio = channel_audio.set_frame_rate(16000)\n",
    "\n",
    "            duration_ms = len(channel_audio)\n",
    "\n",
    "            # x-second window, y-second step\n",
    "            window_size = 1000  # in milliseconds\n",
    "            step_size = 500     # in milliseconds\n",
    "\n",
    "            for start_ms in range(0, duration_ms - window_size + 1, step_size):\n",
    "                end_ms = start_ms + window_size\n",
    "                chunk = channel_audio[start_ms:end_ms]\n",
    "                chunks.append(chunk)\n",
    "\n",
    "                # Record metadata\n",
    "                metadata.append({\n",
    "                    \"file\": os.path.basename(input_file),\n",
    "                    \"channel\": channel_index + 1,\n",
    "                    \"start_ms\": start_ms,\n",
    "                    \"end_ms\": end_ms\n",
    "                })\n",
    "            #break # channel\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error during splitting: {input_file} - {e}\")\n",
    "\n",
    "    return chunks, metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bed7650e-c78e-4e44-8263-7501818c57c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict_audio_chunk(chunk, model, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Filter function that decides whether the given audio chunk contains a mosquito sound.\n",
    "    \"\"\"\n",
    "    data = chunk.get_array_of_samples()\n",
    "    dtype = data.typecode  # The type of the array, e.g., 'h' or 'i'\n",
    "    y = np.array(data, dtype=np.float32)  # Always convert to float32\n",
    "\n",
    "    # Normalization depending on the data type\n",
    "    if dtype == 'h':  # 16-bit integer\n",
    "        y = y / (2**15)  # Normalize between -1 and 1\n",
    "    elif dtype == 'i':  # 32-bit integer\n",
    "        y = y / (2**31)  # Normalize between -1 and 1\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported data format: {dtype}\")\n",
    "        \n",
    "    #y = np.array(chunk.get_array_of_samples(), dtype=np.float32) / (2**15)\n",
    "    sr = chunk.frame_rate\n",
    "\n",
    "    # 100 Hz high-pass filtering\n",
    "    #y = highpass_filter(y, sr)\n",
    "\n",
    "    #print(chunk)\n",
    "    #print(y)\n",
    "\n",
    "    inputs = processor(y, sampling_rate=16000, return_tensors=\"pt\", padding=True)\n",
    "    #print(inputs)\n",
    "    inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "\n",
    "    #print(model(**inputs))\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    #predicted_class = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "    # Calculate probabilities with softmax\n",
    "    probabilities = F.softmax(logits, dim=-1)\n",
    "    #print(probabilities)\n",
    "    \n",
    "    # Probabilities of class 1 for all elements in the batch\n",
    "    class_1_probabilities = probabilities[:, 1]\n",
    "    \n",
    "    # Logical tensor: which element is greater than or equal to 0.5?\n",
    "    thresholded = class_1_probabilities >= threshold\n",
    "\n",
    "    return thresholded[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91239919-56f8-4f37-8508-776877fbd6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def anal_chunks(chunks, output_dir, base_filename, metadata, model, b_save=False):\n",
    "def anal_chunks(chunks, output_dir, base_filename, metadata, model, classification_threshold=0.5, b_save=False):\n",
    "    \"\"\"\n",
    "    Save chunks to the specified folder with numbering.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    not_selected_dir = os.path.join(os.path.dirname(output_dir), os.path.basename(output_dir) + \"_not_selected\")\n",
    "    os.makedirs(not_selected_dir, exist_ok=True)\n",
    "\n",
    "    #speech_dir = os.path.join(os.path.dirname(output_dir), os.path.basename(output_dir) + \"_speech\")\n",
    "    #os.makedirs(speech_dir, exist_ok=True)\n",
    "\n",
    "    sound_idxs=[]\n",
    "\n",
    "    for idx, chunk in enumerate(chunks):\n",
    "        md=metadata[idx]\n",
    "\n",
    "        ch=md['channel']\n",
    "        start=str(int(md['start_ms']))\n",
    "        \n",
    "        #if filter_speech(chunk):\n",
    "        #    if b_save:\n",
    "        #        chunk_speech_file = os.path.join(speech_dir, f\"{base_filename}_{ch}_{start}.wav\")            \n",
    "                #chunk.export(chunk_speech_file, format=\"wav\", parameters=[\"-ar\", \"16000\", \"-ac\", \"1\", \"-sample_fmt\", \"s16\"])\n",
    "\n",
    "        #    if idx % 50 == 0:\n",
    "        #        pass\n",
    "                #print(f\"{idx}: Saved chunk (SPEECH): {chunk_speech_file}\")\n",
    "        #    continue\n",
    "        \n",
    "        if predict_audio_chunk(chunk, model, threshold=classification_threshold):\n",
    "            sound_idxs.append(idx)\n",
    "\n",
    "            if b_save:\n",
    "                chunk_output_file = os.path.join(output_dir, f\"{base_filename}_{ch}_{start}.wav\")\n",
    "                chunk.export(chunk_output_file, format=\"wav\", parameters=[\"-ar\", \"16000\", \"-ac\", \"1\", \"-sample_fmt\", \"s16\"])\n",
    "\n",
    "            if idx % 10 == 0:\n",
    "                pass\n",
    "                print(f\"{idx}: Saved chunk (MOSQUITO SOUND): {chunk_output_file}\")\n",
    "        else:\n",
    "            if b_save:\n",
    "                not_selected_file = os.path.join(not_selected_dir, f\"{base_filename}_{ch}_{start}.wav\")\n",
    "                #chunk.export(not_selected_file, format=\"wav\", parameters=[\"-ar\", \"16000\", \"-ac\", \"1\", \"-sample_fmt\", \"s16\"])\n",
    "\n",
    "            if idx % 50 == 0:\n",
    "                pass\n",
    "                #print(f\"{idx}: Not selected chunk: {not_selected_file}\")\n",
    "\n",
    "        #break\n",
    "        \n",
    "    return sound_idxs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7c1643-b0ce-48ce-b447-63a7a7395a49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28320c86-8e40-4d36-995c-641b5ae8cd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: ./szunyog_hangok_25_01_14/Test0495.wav, Number of channels: 4\n",
      "200: Saved chunk (MOSQUITO SOUND): ./szunyog_hangok_25_01_14_preprocessed_database_AST\\Test0495.wav_1_100000.wav\n",
      "640: Saved chunk (MOSQUITO SOUND): ./szunyog_hangok_25_01_14_preprocessed_database_AST\\Test0495.wav_1_320000.wav\n",
      "670: Saved chunk (MOSQUITO SOUND): ./szunyog_hangok_25_01_14_preprocessed_database_AST\\Test0495.wav_1_335000.wav\n",
      "1060: Saved chunk (MOSQUITO SOUND): ./szunyog_hangok_25_01_14_preprocessed_database_AST\\Test0495.wav_1_530000.wav\n",
      "1240: Saved chunk (MOSQUITO SOUND): ./szunyog_hangok_25_01_14_preprocessed_database_AST\\Test0495.wav_1_620000.wav\n",
      "1280: Saved chunk (MOSQUITO SOUND): ./szunyog_hangok_25_01_14_preprocessed_database_AST\\Test0495.wav_1_640000.wav\n",
      "1370: Saved chunk (MOSQUITO SOUND): ./szunyog_hangok_25_01_14_preprocessed_database_AST\\Test0495.wav_2_5500.wav\n",
      "1440: Saved chunk (MOSQUITO SOUND): ./szunyog_hangok_25_01_14_preprocessed_database_AST\\Test0495.wav_2_40500.wav\n",
      "1560: Saved chunk (MOSQUITO SOUND): ./szunyog_hangok_25_01_14_preprocessed_database_AST\\Test0495.wav_2_100500.wav\n",
      "1690: Saved chunk (MOSQUITO SOUND): ./szunyog_hangok_25_01_14_preprocessed_database_AST\\Test0495.wav_2_165500.wav\n",
      "1780: Saved chunk (MOSQUITO SOUND): ./szunyog_hangok_25_01_14_preprocessed_database_AST\\Test0495.wav_2_210500.wav\n",
      "1990: Saved chunk (MOSQUITO SOUND): ./szunyog_hangok_25_01_14_preprocessed_database_AST\\Test0495.wav_2_315500.wav\n",
      "2000: Saved chunk (MOSQUITO SOUND): ./szunyog_hangok_25_01_1A_preprocessed_database_AST\\Test0495.wav_2_320500.wav\n",
      "2020: Saved chunk (MOSQUITO SOUND): ./szunyog_hangok_25_01_14_preprocessed_database_AST\\Test0495.wav_2_330500.wav\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fns=glob.glob(os.path.join(input_root,\"*.wav\"))\n",
    "#print(fns)\n",
    "\n",
    "# Start time measurement\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "for idx, input_fn in enumerate(fns):\n",
    "\n",
    "    base_filename=os.path.basename(input_fn)\n",
    "    output_file = os.path.join(output_root, f\"{base_filename[:-4]}.csv\")\n",
    "\n",
    "    \n",
    "    #If the output file already exists, continue with the next file\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"already done: {input_fn}\")\n",
    "        continue\n",
    "\n",
    "    # Splitting and filtering\n",
    "    #print(\"split begun\")\n",
    "    chunks, metadata = split_audio_chunks(input_fn)\n",
    "    #print(\"split finished\")\n",
    "    \n",
    "    \n",
    "    if len(chunks)>0:\n",
    "        # index contains mosquito segments, and the function also writes wavs if b_save=1\n",
    "        #sound_idxs=anal_chunks(chunks, output_root, base_filename, metadata, model, b_save=True)\n",
    "        sound_idxs=anal_chunks(chunks, output_root, base_filename, metadata, model, classification_threshold=classification_threshold, b_save=b_save_segments)\n",
    "\n",
    "        if b_write_csv:\n",
    "            if len(sound_idxs)>0:\n",
    "                # Create Metadata DataFrame\n",
    "                out_df = pd.DataFrame(metadata)\n",
    "                \n",
    "                # Filter based on analyzed indices\n",
    "                out_df = out_df.iloc[sound_idxs]\n",
    "            \n",
    "                # Save results to file\n",
    "                out_df.to_csv(output_file, index=False)\n",
    "            else:\n",
    "                # Empty csv\n",
    "                with open(output_file, mode=\"w\") as file:\n",
    "                    file.write(\"file,channel,start_ms,end_ms\\n\")\n",
    "                print(\"no mosquito sound found.\")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"finished, time: {end_time - start_time:.6f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcba944-cb50-40e6-a0cc-deecaf101773",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8fc5b9-0ff4-4d6a-a258-8c5b7b12cd4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
